# OpenTelemetry Collector Configuration for k3d
# Production-ready base configuration with k3d-specific overrides

# =============================================================================
# Deployment Mode
# =============================================================================
mode: deployment

# =============================================================================
# Service Configuration
# =============================================================================
service:
  # ClusterIP is sufficient - Beyla connects via hostPort (localhost:4317)
  type: ClusterIP

# =============================================================================
# Image Configuration
# =============================================================================
image:
  repository: otel/opentelemetry-collector-contrib
  tag: 0.143.1

# =============================================================================
# Monitoring
# =============================================================================
serviceMonitor:
  enabled: true
prometheusRule:
  enabled: false

# =============================================================================
# Collector Configuration
# =============================================================================
config:
  # ---------------------------------------------------------------------------
  # Receivers
  # ---------------------------------------------------------------------------
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

  # ---------------------------------------------------------------------------
  # Processors
  # ---------------------------------------------------------------------------
  processors:
    batch:
      send_batch_size: 1000
      send_batch_max_size: 1500
      timeout: 10s
    resource:
      attributes:
        - key: cluster.name
          # TODO: (k3d) Change to actual cluster name in production
          value: k8s-local
          action: upsert
    memory_limiter:
      check_interval: 1s
      limit_mib: 400
      spike_limit_mib: 100
    # Kubernetes attributes processor - extracts metadata from K8s API
    k8sattributes:
      auth_type: "serviceAccount"
      passthrough: false
      extract:
        metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.deployment.name
          - k8s.node.name
        labels:
          - tag_name: app
            key: app.kubernetes.io/name
            from: pod
          - tag_name: version
            key: app.kubernetes.io/version
            from: pod
      pod_association:
        - sources:
            - from: resource_attribute
              name: k8s.pod.ip
        - sources:
            - from: resource_attribute
              name: k8s.pod.uid
        - sources:
            - from: connection
    # Transform processor to map Fluent Bit kubernetes metadata to OTEL semantic conventions
    # Fluent Bit sends kubernetes metadata as a nested Map: attributes["kubernetes"]["namespace_name"]
    # This processor MUST run BEFORE k8sattributes to set the correct pod identification
    transform/logs:
      error_mode: ignore
      log_statements:
        - context: log
          statements:
            # Map Fluent Bit kubernetes metadata (nested Map) to OTEL resource attributes
            # Set k8s.pod.ip first so k8sattributes can look up the correct pod
            - set(resource.attributes["k8s.pod.ip"], attributes["kubernetes"]["pod_ip"]) where attributes["kubernetes"]["pod_ip"] != nil and resource.attributes["k8s.pod.ip"] == nil
            - set(resource.attributes["k8s.pod.uid"], attributes["kubernetes"]["pod_id"]) where attributes["kubernetes"]["pod_id"] != nil and resource.attributes["k8s.pod.uid"] == nil
            - set(resource.attributes["k8s.namespace.name"], attributes["kubernetes"]["namespace_name"]) where attributes["kubernetes"]["namespace_name"] != nil and resource.attributes["k8s.namespace.name"] == nil
            - set(resource.attributes["k8s.pod.name"], attributes["kubernetes"]["pod_name"]) where attributes["kubernetes"]["pod_name"] != nil and resource.attributes["k8s.pod.name"] == nil
            - set(resource.attributes["k8s.container.name"], attributes["kubernetes"]["container_name"]) where attributes["kubernetes"]["container_name"] != nil and resource.attributes["k8s.container.name"] == nil
            - set(resource.attributes["service.name"], attributes["kubernetes"]["pod_name"]) where attributes["kubernetes"]["pod_name"] != nil and resource.attributes["service.name"] == nil

  # ---------------------------------------------------------------------------
  # Exporters
  # ---------------------------------------------------------------------------
  exporters:
    # Prometheus exporter for metrics
    prometheus:
      endpoint: "0.0.0.0:8889"
      send_timestamps: true
      metric_expiration: 180m
      enable_open_metrics: true
    # Debug exporter for troubleshooting
    debug:
      verbosity: detailed
      sampling_initial: 2
      sampling_thereafter: 500
    # Loki exporter for logs
    otlphttp/loki:
      endpoint: "http://loki.monitoring.svc.cluster.local:3100/otlp"
      tls:
        insecure: true
    # Tempo exporter for traces
    otlp/tempo:
      endpoint: "tempo.monitoring.svc.cluster.local:4317"
      tls:
        insecure: true
      sending_queue:
        enabled: true
        num_consumers: 10
        queue_size: 5000
      retry_on_failure:
        enabled: true
        initial_interval: 5s
        max_interval: 30s
        max_elapsed_time: 300s

  # ---------------------------------------------------------------------------
  # Extensions
  # ---------------------------------------------------------------------------
  extensions:
    health_check:
      endpoint: "0.0.0.0:13133"
    pprof:
      endpoint: 0.0.0.0:1777
    zpages:
      endpoint: 0.0.0.0:55679

  # ---------------------------------------------------------------------------
  # Service Pipelines
  # ---------------------------------------------------------------------------
  service:
    extensions: [health_check, pprof, zpages]
    pipelines:
      # Metrics pipeline
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, k8sattributes, resource, batch]
        exporters: [prometheus]
      # Traces pipeline
      traces:
        receivers: [otlp]
        processors: [memory_limiter, k8sattributes, resource, batch]
        exporters: [otlp/tempo]
      # Logs pipeline
      # NOTE: transform/logs must run BEFORE k8sattributes to set resource attributes
      # from Fluent Bit's kubernetes metadata. Otherwise, k8sattributes uses the
      # sender's (Fluent Bit DaemonSet) namespace instead of the actual log source.
      logs:
        receivers: [otlp]
        processors: [memory_limiter, transform/logs, k8sattributes, resource, batch]
        exporters: [otlphttp/loki]

# =============================================================================
# Port Configuration
# =============================================================================
ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    protocol: TCP
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    protocol: TCP
  metrics:
    enabled: true
    containerPort: 8888
    servicePort: 8888
    protocol: TCP
  prom-metrics:
    enabled: true
    containerPort: 8889
    servicePort: 8889
    protocol: TCP

# =============================================================================
# Resource Limits
# =============================================================================
resources:
  limits:
    cpu: 256m
    memory: 512Mi
  requests:
    cpu: 128m
    memory: 256Mi

# =============================================================================
# RBAC Configuration for k8sattributes processor
# =============================================================================
clusterRole:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["pods", "namespaces", "nodes"]
      verbs: ["get", "watch", "list"]
    - apiGroups: ["apps"]
      resources: ["deployments", "replicasets", "daemonsets", "statefulsets"]
      verbs: ["get", "watch", "list"]
